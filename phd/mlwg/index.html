<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Machine Learning - Working group</title>
</head>

<body>
    <h1 style="text-align: center;">Groupe de travail GRAVIR sur
        l'apprentissage automatique<br>
    </h1>


    <h2>Past sessions slides</h2>

    <ul>

        <li> <a href=Clustering2.pdf> Clustering </a>(Oliver Brdiczka) </li>
        <li> <a href=MLWG2_BayesianLearning_dangauthier.pdf> Bayesian Learning </a> (Pierre Dangauthier)
            <a href=apprentissagebaymlwgsessiondeux.html>Details</a>
        </li>
        <li> <a href=kalman.pdf> Kalman filter </a> (Christopher Tay Meng Keat)<a
                href=kalmanmlwgsessiontrois.html>Details</a></li>
        <li> <a href=MLWG_4_Associative_mem.pdf> Associative memories</a> (Humberto Sossa)
            <a href=associativelearningmlwgsessionquatre.html>Details</a>
        </li>
        <li> <a href=Competitive_Learning.pdf>Competitive Learning </a> Competitive Learning (Dizan Vasquez) <a
                href=growingneuralgazmlwgsessioncinq.html>Details</a></li>
        <li> <a href=svm.pdf> SVM </a>(Eric Nowak) <a href=svmmlwg.html>Details</a></li>
    </ul>

    <h2>Introduction</h2>
    Quelques th&eacute;sards extr&egrave;mement motiv&eacute;s pour faire
    apprendre des machines (&agrave; leur place ?) se lancent dans
    l'organisation hebdomadaire d'un "s&eacute;minaire" informel sur le
    th&egrave;me ouvert du "machine learning".
    <br>
    <br>
    But pragmatique: Aider les participants dans leur travail de recherche,
    en les informant sur les techniques "&eacute;tat de l'art", sur les
    r&eacute;f&eacute;rences indispensables, et en leur permettant de
    prendre un peu de recul, les aider &agrave; choisir une technique pour
    leur th&egrave;se, etc...<br>
    <br>
    Nous sommes 4 doctorants pr&egrave;ts &agrave; lancer ces
    r&eacute;unions, mais si vous &ecirc;tes intress&eacute;s pour
    assister, ou mieux, pour intervenir, vous &ecirc;tes le tr&egrave;s
    bien venu. D'autant plus qu'on ne connait quasi rien aux sujets ci
    dessous... <br>

    <h2>Programme</h2>

    <br>
    Les reunion ont d'habitude lieu en salle C207 les mercredi a 16h l'INRIA de Montbonnot, sauf avis contraire sur la
    mailing liste.

    <br>

    <h2>Moyens</h2>
    <span style="font-weight: bold;">Mailing liste</span>: <a href="mailto:-----------">xxx@xxxxx</a>
    <br>
    Cette liste nous permettra d'annoncer les nouvelles sessions, etc...<br>
    Inscrivez vous sur <a href="xxxxxxx">http://xxxxxxxxxxxxxxx</a><br>
    <br>
    <h2>Détails </h2>
    <h3>Principes</h3>
    <ol>
        <li>&nbsp;Ouvert à tout le monde, spécialement aux
            thésards, DEA, stagiaires de tous poils
        </li>
        <li>&nbsp;Réunion <span style="font-weight: bold;">TRÈS</span>
            informelle autour d'un caf&eacute;
        </li>
        <li>&nbsp;Tous les mardis à 16 heures
        </li>
        <li>&nbsp;La salle dépendra du (probablement faible) nombre de
            participants
        </li>
        <li>&nbsp;Présentation de <big><span style="font-weight: bold;">20 min</span></big> d'un "intervenant"
        </li>
        <li>&nbsp;N'importe qui peut être intervenant : considérez ce
            mail comme un <span style="font-weight: bold;">APPEL À PARTICIPATION</span> !
        </li>
        <li>&nbsp;Discussion, question : pas plus de <big><span style="font-weight: bold;">15-20 minutes</span></big>
        </li>
        <li>&nbsp;Langue: français, sauf si anglophones récalcitrants
        </li>
        <li>&nbsp;Ça doit être rapide, et prendre peu de temps
            aux participants et à l'intervenant
        </li>
        <li>&nbsp;L'intervenant est soit un "spécialiste", soit un
            jeune souhaitant se former sur le sujet
        </li>
        <li>&nbsp;Une intervention typique pourra se composer de:
        </li>
    </ol>
    <ul style="margin-left: 40px;">
        <li>&nbsp;&nbsp; présentation de la technique
        </li>
        <li>&nbsp;&nbsp; domaine d'application
        </li>
        <li>&nbsp;&nbsp; REFERENCES classiques du domaine,
        </li>
        <li>&nbsp;&nbsp; explication intuitive
        </li>
        <li>&nbsp;&nbsp; éventuellement, on entre dans les détails
            algorithmiques
        </li>
        <li>&nbsp;&nbsp; un exemple simple
        </li>
        <li>&nbsp;&nbsp; caractérisation de la méthode dans le cadre général
            de l'apprentissage
        </li>
        <li>&nbsp;&nbsp; discussion
        </li>
    </ul>
    <h2>Thématiques</h2>
    &nbsp;Liste (ouverte) de thèmes envisagés
    <br>
    <ol>
        <li>&nbsp;&nbsp; apprentissage en général
        </li>
        <li>&nbsp;&nbsp; apprentissage bayésien (prior/likelihood,
            réseaux bayésiens)
        </li>
        <li>&nbsp;&nbsp; <span style="font-weight: bold;">HMM</span>: Hiden
            Markov Models
        </li>
        <li>&nbsp;&nbsp; <span style="font-weight: bold;">EM</span>:
            Expectation/Maximisation
        </li>
        <li>&nbsp;&nbsp; Comment bien discrétiser
        </li>
        <li>&nbsp;&nbsp; KALMAN filtering, Extended <span style="font-weight: bold;">KF</span>
        </li>
        <li>&nbsp;&nbsp; <span style="font-weight: bold;">MRF</span>: Markov
            Random Fields
        </li>
        <li>&nbsp;&nbsp; Particle Filtering
        </li>
        <li>&nbsp;&nbsp; <span style="font-weight: bold;">MDP</span>, <span style="font-weight: bold;">POMDP</span>:
            (Partially Observable) Markov
            Decision Process
        </li>
        <li>&nbsp;&nbsp; Neural nets
        </li>
        <li>&nbsp;&nbsp; <span style="font-weight: bold;">SVM</span>:
            Support Vecto Machine - Vapnik learning theory
        </li>
        <li>&nbsp;&nbsp; <span style="font-weight: bold;">GA</span>: Genitic
            algorithms
        </li>
        <li>&nbsp;&nbsp; Decision trees (ID3)<br>
        </li>
        <li>&nbsp;&nbsp; Boosting
        </li>
        <li>&nbsp;&nbsp; Relevance Vector Machines
        </li>
        <li>&nbsp;&nbsp; <span style="font-weight: bold;">MCMC</span>:
            Markov Chain Monte Calo Methods
        </li>
        <li>&nbsp;&nbsp; <span style="font-weight: bold;">RL</span>:
            Reinforcement learning
        </li>
        <li>&nbsp;&nbsp; Clustering
        </li>
        <li>&nbsp;&nbsp; Knowledge base
        </li>
        <li>&nbsp;&nbsp; Automatic generation of a PhD thesis
        </li>
        <li>&nbsp;&nbsp; Bayesian Neural NETs, Gaussian Process
        </li>
        <li>&nbsp;&nbsp; Occam Razor, et autres philosophies</li>
        <li>.... (&agrave; vous de voir)<br>
        </li>
    </ol>
    &nbsp;&nbsp; <br>

    <h2>Links</h2>
    <h3>Apprentissage bayésien ou statistique</h3>
    <ul>
        <li><a href="http://research.microsoft.com/~heckerman/">Heckerman</a></li>
        <li><a href="http://www.research.microsoft.com/~minka/papers/">Minka</a></li>
        <li><a href="http://mplab.ucsd.edu/tutorials/tutorials">Tutoriels</a></li>
        <li><a href="http://www.gatsby.ucl.ac.uk/~zoubin/course04/index.html">Unsupervised Learning Course
                Ghahramani</a></li>
    </ul>

    <h3>Neural networks related</h3>
    <ul>
        <li><a href="http://www.gc.ssr.upm.es/inves/neural/ann1/unsupmod/CompetLe/kohonen.htm">Kohonen's self-organising
                feature map</a></li>
    </ul>

    <h3>Machine Learning</h3>
    <ul>
        <li><a href="http://www.neuro-it.net/index_html/Resources/Sites/SitesOfTutorials">Several tutorials (Neuro-iT
                Site)</a></li>
        <li><a href="http://www.aaai.org/AITopics/html/machine.html">AAAI</a></li>
        <li><a href="http://hunch.net/">Langford</a> C'est un blog !</li>
        <li><a href="http://www.stanford.edu/class/cs229/materials.html">Cours de Stanford</a></li>
        <li><a href="http://yaroslavvb.blogspot.com/2005/02/machine-learning-reading-groups.html">Bulatov</a> un autre
            blog, avec une liste de "Machine Learning reading groups"</li>
        <li><a href="http://www.stat.cmu.edu/~minka/statlearn/glossary/">A Statistical Learning/Pattern Recognition
                Glossary</a></li>
        <li><a href="http://www.amsta.leeds.ac.uk/~charles/statlog/">Machine Learning, Neural and Statistical
                Classification</a> out of print free book on the web by D. Michie, D.J. Spiegelhalter, C.C. Taylor</li>
    </ul>

    <h3>Reinforcement Learning</h3>
    <ul>
        <li><a href="http://neuromancer.eecs.umich.edu/cgi-bin/twiki/view/Main/WebHome">Wiki</a> de University of
            Michigan Reinforcement Learning Group</li>
        <li><a href="http://ai.stanford.edu/people/nilsson/mlbook.html">Nils J. Nilsson</a> lecture notes on machine
            learning (currently draft)</li>
    </ul>
    <br>
    <br>
</body>

</html>
